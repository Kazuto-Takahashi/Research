{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Pb7KUxBTL3FQ",
        "F834LYBlN6ym",
        "eoaQue-D6Srm",
        "08GnFgTerWAt",
        "I0ersTL6uiPt"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kazuto-Takahashi/Research/blob/main/SimCLR_by_Resnet_ipynb_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Data"
      ],
      "metadata": {
        "id": "Pb7KUxBTL3FQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yc9oTR_5LutH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler as lr_scheduler\n",
        "import torch.utils as utils\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ここでdata augumentation\n",
        "class CutOut:\n",
        "    def __init__(self, size=24):\n",
        "        self.size = size\n",
        "    def __call__(self, img):\n",
        "        img = np.array(img)\n",
        "        h = torch.randint(0, 96-self.size, (1,))\n",
        "        w = torch.randint(0, 96-self.size, (1,))\n",
        "        img[:, h:h + self.size, w:w + self.size] = 0\n",
        "        img = transforms.ToPILImage()(img)\n",
        "        return img\n",
        "\n",
        "class ImgAugmentation:\n",
        "    def __init__(self):\n",
        "        cutout = CutOut()\n",
        "        color_jitter = transforms.ColorJitter(0.5, 0.5, 0.5, 0.5)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomApply([cutout], p=0.5),\n",
        "            transforms.RandomApply([color_jitter], p=0.8),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "    def __call__(self, x):\n",
        "        return self.transform(x), self.transform(x)\n",
        "\n",
        "#train = datasets.CIFAR10(root='./data', train=True, transform=ImgAugmentation(), download=True)\n",
        "#test = datasets.CIFAR10(root='./data', train=False, transform=ImgAugmentation(), download=True)\n",
        "#all = ConcatDataset([train, test])\n",
        "#all_loader = DataLoader(all, batch_size=512, shuffle=True, drop_last=True)#60,000data\n",
        "\n",
        "dataset = datasets.STL10('./data', split='unlabeled', transform=ImgAugmentation(), download=True)\n",
        "data_loader = DataLoader(dataset, batch_size=512, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "mNPEs8QPM3hK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "8a19499b-451b-4dca-b2ce-182ccf3c169e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [05:21<00:00, 8211155.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/stl10_binary.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "F834LYBlN6ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c, down_sampling=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if down_sampling:\n",
        "            self.stride = 2\n",
        "            self.convds = nn.Conv2d(in_c, out_c, 2, 2)\n",
        "        else:\n",
        "            self.stride = 1\n",
        "        self.down_sampling = down_sampling\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, 3, self.stride, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_c)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, 3, 1, 1)\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        if self.down_sampling:\n",
        "            skip = self.convds(skip)\n",
        "        else: pass\n",
        "        x += skip\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet18, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, 2, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.block11 = BasicBlock(64, 64)\n",
        "        self.block12 = BasicBlock(64, 64)\n",
        "        self.block21 = BasicBlock(64, 128, True)\n",
        "        self.block22 = BasicBlock(128, 128)\n",
        "        self.block31 = BasicBlock(128, 256, True)\n",
        "        self.block32 = BasicBlock(256, 256)\n",
        "        self.block41 = BasicBlock(256, 512, True)\n",
        "        self.block42 = BasicBlock(512, 512)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        #1\n",
        "        x = self.conv1(x) #[3, 96, 96] -> [64, 48, 48]\n",
        "        x = self.relu(x)\n",
        "        #2\n",
        "        x = self.maxpool(x) #[64, 48, 48] -> [64, 24, 24]\n",
        "        x = self.block11(x) #[64, 24, 24] -> [64, 24, 24]\n",
        "        x = self.block12(x)\n",
        "        #3\n",
        "        x = self.block21(x) #[64, 24, 24] -> [128, 12, 12]\n",
        "        x = self.block22(x)\n",
        "        #4\n",
        "        x = self.block31(x) #[128, 12, 12] -> [256, 6, 6]\n",
        "        x = self.block32(x)\n",
        "        #5\n",
        "        x = self.block41(x) #[256, 6, 6] -> [512, 3, 3]\n",
        "        x = self.block42(x)\n",
        "        #6\n",
        "        x = self.avgpool(x) #[512, 3, 3] -> [512, 1, 1]\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "zlM47Rrzw9Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super(SimCLR, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.Linear(512, 64)\n",
        "        )\n",
        "\n",
        "    def forward(self, xi, xj):#([b, c, h, w], [b, c, h, w]) -> ([b, dim], [b, dim])\n",
        "        hi = self.encoder(xi)\n",
        "        hj = self.encoder(xj)\n",
        "        zi = self.projector(hi)\n",
        "        zj = self.projector(hj)\n",
        "        return zi, zj"
      ],
      "metadata": {
        "id": "mCUqwWbp-s55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NT-Xent Loss"
      ],
      "metadata": {
        "id": "eoaQue-D6Srm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NT_Xent(nn.Module):\n",
        "    def __init__(self, batch_size=512):\n",
        "        super(NT_Xent, self).__init__()\n",
        "        self.device = torch.device('cuda')\n",
        "        self.batch_size = batch_size\n",
        "        self.mask = self.make_mask(batch_size)\n",
        "        self.similarity = nn.CosineSimilarity(dim=2)\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "    def make_mask(self, batch_size):\n",
        "        mask = torch.ones((2*batch_size, 2*batch_size))\n",
        "        mask = mask.fill_diagonal_(0)\n",
        "        ones = torch.ones((batch_size))\n",
        "        mask = mask - torch.diag(ones, batch_size) - torch.diag(ones, -batch_size)\n",
        "        return mask.bool()\n",
        "\n",
        "    def forward(self, zi, zj):\n",
        "        z = torch.cat((zi, zj), dim=0)#z = [2b, 2f]\n",
        "\n",
        "        sim = 10 * self.similarity(z.unsqueeze(1), z.unsqueeze(0))#sim = [2b, 2b]\n",
        "        sim_ij = torch.diag(sim, self.batch_size)#sim_ij = [b, 1]\n",
        "        sim_ji = torch.diag(sim, -self.batch_size)#sim_ji = [b, 1]\n",
        "\n",
        "        positive = torch.cat((sim_ij, sim_ji), dim=0).reshape(2*self.batch_size, 1)#positive = [2b, 1]\n",
        "        negative = sim[self.mask].reshape(2*self.batch_size, -1)#negative = [2b, 2b-2]\n",
        "\n",
        "        target = torch.zeros(2*self.batch_size, dtype=torch.long).to(self.device)#index=0が正解クラス\n",
        "        logits = torch.cat((positive, negative), dim=1)#pred = [2b, 2b-1], index=0にpositiveそれ以外はnegative\n",
        "        loss = self.criterion(logits, target)\n",
        "        loss /= 2 * self.batch_size\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VvakuHFO8Ozx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint"
      ],
      "metadata": {
        "id": "08GnFgTerWAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(epoch, model, optimizer, scheduler, criterion):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_sd': model.state_dict(),\n",
        "        'optimizer_sd': optimizer.state_dict(),\n",
        "        'scheduler_sd': scheduler.state_dict(),\n",
        "        'criterion': criterion\n",
        "    }\n",
        "    torch.save(checkpoint, f'simclr_epoch{epoch}_resnet.pth')\n",
        "\n",
        "def load_checkpoint(filename, model, optimizer, scheduler):\n",
        "    checkpoint = torch.load(filename)\n",
        "\n",
        "    epoch = checkpoint['epoch']\n",
        "    criterion = checkpoint['criterion']\n",
        "    model.load_state_dict(checkpoint['model_sd'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_sd'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_sd'])\n",
        "\n",
        "    return epoch, criterion"
      ],
      "metadata": {
        "id": "Ic-zN-ALrYUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contrastive Learning"
      ],
      "metadata": {
        "id": "I0ersTL6uiPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = ResNet18()\n",
        "simclr = SimCLR(encoder)\n",
        "optimizer = optim.Adam(simclr.parameters())\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=8, eta_min=1e-5)\n",
        "nt_xent = NT_Xent(512)"
      ],
      "metadata": {
        "id": "j13sIJYiuj7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch, loss = load_checkpoint('simclr_epoch10_resnet.pth', simclr, optimizer, scheduler)"
      ],
      "metadata": {
        "id": "ISvunvD33dyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1789c515-4cbe-44df-b103-dabcafbb78f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-daeb58454062>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "start_epochs = 0\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "simclr.to(device)\n",
        "nt_xent.to(device)\n",
        "\n",
        "simclr.train()\n",
        "for epoch in range(start_epochs, epochs):\n",
        "    loss_epoch = 0\n",
        "    for (xi, xj), _ in tqdm(data_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        xi, xj = xi.to(device), xj.to(device)\n",
        "        zi, zj = simclr(xi, xj)\n",
        "        zi, zj = zi.to(device), zj.to(device)\n",
        "\n",
        "        loss = nt_xent(zi, zj)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_epoch += loss.item()\n",
        "    scheduler.step()\n",
        "    print(f'Epoch{epoch} : loss = {loss_epoch}')\n",
        "#T4 GPU\n",
        "#VGG-5 | epoch=8 | 2min/epoch | loss(0) = 1.1277, loss(4) = 0.146, loss(6) = 0.1277, loss(7) = 0.1233\n",
        "#ResNet18 | epoch=10 | 8min/epoch | loss(0) = 821(/195=4.21), loss(2) = 1.584, loss(4) = 0.7967, loss(6) = 0.541, loss(9) = 0.492"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKNWke_uvFbG",
        "outputId": "e058f6fd-d2e8-4b7d-c632-156a8eb74a3e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [08:03<00:00,  2.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch0 : loss = 821.246425151825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [08:02<00:00,  2.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch1 : loss = 378.4808655977249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [07:58<00:00,  2.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch2 : loss = 308.9420028924942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [07:59<00:00,  2.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch3 : loss = 207.56589543819427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [07:58<00:00,  2.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch4 : loss = 155.36485081911087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [08:00<00:00,  2.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch5 : loss = 121.89358973503113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [07:55<00:00,  2.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch6 : loss = 105.62774163484573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [07:59<00:00,  2.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch7 : loss = 98.48255547881126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [07:56<00:00,  2.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch8 : loss = 96.89931404590607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [07:57<00:00,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch9 : loss = 96.07199031114578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_checkpoint(10, simclr, optimizer, scheduler, loss_epoch)"
      ],
      "metadata": {
        "id": "xZ7fCLqMtyhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier"
      ],
      "metadata": {
        "id": "P8kg-gorqMMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_inf = datasets.STL10('./data', split='train', transform=transform, download=True)\n",
        "test_inf = datasets.STL10('./data', split='test', transform=transform)\n",
        "\n",
        "train_inf_loader = DataLoader(train_inf, batch_size=128, shuffle=True, drop_last=True)\n",
        "test_inf_loader = DataLoader(test_inf, batch_size=128, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3PmjK12daDo",
        "outputId": "b7afc95e-e385-4226-dd70-da867dd8e125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [06:07<00:00, 7188133.48it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/stl10_binary.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = nn.Sequential(\n",
        "    nn.Linear(512, 10)\n",
        ")"
      ],
      "metadata": {
        "id": "OeW9n88CZeWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_inf = optim.Adam(classifier.parameters())\n",
        "scheduler_inf = lr_scheduler.CosineAnnealingLR(optimizer, T_max=4, eta_min=1e-4)\n",
        "criterion_inf = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs_inf = 4\n",
        "start_epochs_inf = 0\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "encoder.to(device)\n",
        "classifier.to(device)\n",
        "\n",
        "N = len(train_inf_loader.dataset)\n",
        "n = len(test_inf_loader.dataset)\n",
        "\n",
        "encoder.eval()\n",
        "for epoch in range(start_epochs_inf, epochs_inf):\n",
        "    tr_loss = 0\n",
        "    tr_corr = 0\n",
        "    classifier.train()\n",
        "    for data, target in tqdm(train_inf_loader):\n",
        "        optimizer_inf.zero_grad()\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            out = encoder(data)\n",
        "        out = classifier(out)\n",
        "        loss = criterion_inf(out, target)\n",
        "        loss.backward()\n",
        "        optimizer_inf.step()\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "        _, pred = out.max(1)\n",
        "        tr_corr += (pred == target).sum().item()\n",
        "    scheduler_inf.step()\n",
        "\n",
        "    ts_loss = 0\n",
        "    ts_corr = 0\n",
        "    classifier.eval()\n",
        "    for data, target in tqdm(test_inf_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            out = encoder(data)\n",
        "            out = classifier(out)\n",
        "            loss = criterion_inf(out, target)\n",
        "        ts_loss += loss.item()\n",
        "        _, pred = out.max(1)\n",
        "        ts_corr += (pred == target).sum().item()\n",
        "    print(f'Epoch{epoch} : {tr_loss}, {tr_corr*100/N} | {ts_loss}, {ts_corr*100/n}')\n",
        "#2min/epoch\n",
        "#49%\n",
        "# linear on resnet_10 = 26%, -> encoder512dimじゃだめか -> Cifar10だからダメ -> STL10で30%!?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvG3Hrqfb63O",
        "outputId": "90528465-9d61-49ca-8fc4-bbdea33b3c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:05<00:00,  7.59it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch0 : 117.35667157173157, 13.24 | 139.58846187591553, 20.4375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:03<00:00, 11.48it/s]\n",
            "100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch1 : 81.9593403339386, 25.3 | 123.93009781837463, 27.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:03<00:00, 11.56it/s]\n",
            "100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch2 : 76.94475972652435, 28.88 | 121.93325006961823, 28.775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:03<00:00, 12.51it/s]\n",
            "100%|██████████| 62/62 [00:05<00:00, 10.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch3 : 74.58009779453278, 30.52 | 117.1057003736496, 31.0875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(classifier.state_dict(), 'classifier4ep_on_8ep.pth')"
      ],
      "metadata": {
        "id": "7u4DC27og9GX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}