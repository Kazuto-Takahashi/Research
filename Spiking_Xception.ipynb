{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "IdPtAZ0hCZ75"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kazuto-Takahashi/Research/blob/main/Spiking_Xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt6eo-Jo_ECp",
        "outputId": "2438f2ff-652f-4e89-ddf3-5896584c19e7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spikingjelly\n",
            "  Downloading spikingjelly-0.0.0.0.14-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (2.5.0+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (4.66.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (0.20.0+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->spikingjelly) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->spikingjelly) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->spikingjelly) (3.0.2)\n",
            "Downloading spikingjelly-0.0.0.0.14-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spikingjelly\n",
            "Successfully installed spikingjelly-0.0.0.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install spikingjelly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler as lrs\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import spikingjelly\n",
        "from spikingjelly.activation_based import neuron, layer as snn, functional as SF\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2 as TF\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "38I9_YFz_cyW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "9MCBbiNbAJ27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SepConv(nn.Module):\n",
        "    def __init__(self, inc, outc, stride=1):\n",
        "        super(SepConv, self).__init__()\n",
        "        self.stride = stride\n",
        "        self.layer = nn.Sequential(\n",
        "            snn.Conv2d(inc, inc, 3, self.stride, 1, groups=inc, bias=False),\n",
        "            neuron.IFNode(),\n",
        "            snn.Conv2d(inc, outc, 1, bias=False)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.layer(x)\n",
        "        return x\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, inc, outc, lif=True):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.down_sample = True if inc != outc else False\n",
        "        self.stride = 2 if self.down_sample else 1\n",
        "        self.conv1x1 = snn.Conv2d(inc, outc, 2, 2, bias=False)\n",
        "\n",
        "        layer = []\n",
        "        layer.append(neuron.IFNode()) if lif else None\n",
        "        layer.append(SepConv(inc, outc, self.stride))\n",
        "        layer.append(snn.BatchNorm2d(outc))\n",
        "        layer.append(neuron.IFNode())\n",
        "        layer.append(SepConv(outc, outc))\n",
        "        layer.append(snn.BatchNorm2d(outc))\n",
        "        self.layer = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer(x)\n",
        "        if self.down_sample:\n",
        "            x = self.conv1x1(x)\n",
        "        out += x\n",
        "        return out\n",
        "\n",
        "class S_Xception(nn.Module):\n",
        "    def __init__(self, T=4):\n",
        "        super(S_Xception, self).__init__()\n",
        "        self.T = T\n",
        "        self.first = nn.Sequential(\n",
        "            snn.Conv2d(3, 32, 3, 2, 1, bias=False),\n",
        "            snn.BatchNorm2d(32),\n",
        "            neuron.IFNode()\n",
        "        )\n",
        "        self.block1 = BasicBlock(32, 64, False)\n",
        "        self.block2 = BasicBlock(64, 64)\n",
        "        self.block3 = BasicBlock(64, 64)\n",
        "        self.block4 = BasicBlock(64, 128)\n",
        "        self.last = nn.Sequential(\n",
        "            SepConv(128, 256),\n",
        "            snn.BatchNorm2d(256),\n",
        "            neuron.IFNode(),\n",
        "            snn.AdaptiveAvgPool2d((1, 1)),\n",
        "            snn.Flatten(),\n",
        "            snn.Linear(256, 10)\n",
        "        )\n",
        "        SF.set_step_mode(self, 'm')\n",
        "\n",
        "    def forward(self, x):# N, C, H, W -> T, N, D\n",
        "        SF.reset_net(self)\n",
        "        x = x.unsqueeze(0).repeat(self.T, 1, 1, 1, 1)\n",
        "        x = self.first(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.last(x)\n",
        "        return x.mean(0)"
      ],
      "metadata": {
        "id": "atgPkMnP1iqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = S_Xception(4)\n",
        "params = sum(p.numel() for p in model.parameters())\n",
        "print(params)"
      ],
      "metadata": {
        "id": "dPVYJ70GXWHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "IdPtAZ0hCZ75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataAugmentation:\n",
        "    def __init__(self):\n",
        "        self.device = device\n",
        "        color_jitter = TF.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
        "        self.tf = TF.Compose([\n",
        "            TF.RandomResizedCrop(32, (0.36, 1)),\n",
        "            TF.RandomHorizontalFlip(p=0.5),\n",
        "            TF.RandomApply([color_jitter], p=0.8),\n",
        "            TF.RandomGrayscale(p=0.2),\n",
        "            TF.ToImage(),\n",
        "            TF.ToDtype(torch.float32, scale=True)\n",
        "        ])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.tf(x), self.tf(x)"
      ],
      "metadata": {
        "id": "aFoKyCZPEfTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(data='cifar10', split='train', batch_size=128, DA=False):\n",
        "    tf = DataAugmentation() if DA else TF.Compose([TF.ToImage(), TF.ToDtype(torch.float32, scale=True)])\n",
        "    if data == 'cifar10':\n",
        "        match split:\n",
        "            case 'train':\n",
        "                data = datasets.CIFAR10('./data', train=True, transform=tf, download=True)\n",
        "            case 'test':\n",
        "                data = datasets.CIFAR10('./data', train=False, transform=tf, download=True)\n",
        "            case 'all':\n",
        "                train = datasets.CIFAR10('./data', train=True, transform=tf, download=True)\n",
        "                test = datasets.CIFAR10('./data', train=False, transform=tf, download=True)\n",
        "                data = ConcatDataset([train, test])\n",
        "    elif data == 'stl10':\n",
        "        match split:\n",
        "            case 'train':\n",
        "                data = datasets.STL10('./data', split='train', transform=tf, download=True)\n",
        "            case 'test':\n",
        "                data = datasets.STL10('./data', split='test', transform=tf, download=True)\n",
        "            case 'all':\n",
        "                data = datasets.STL10('./data', split='unlabeled', transform=tf, download=True)\n",
        "    else:\n",
        "        print(f'{data} is not supported >_<. cifar10 or stl10 is supported')\n",
        "    loader = DataLoader(data, batch_size, shuffle=True, drop_last=True, num_workers=2)\n",
        "    return loader"
      ],
      "metadata": {
        "id": "T8LqDRHJCdbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_(loader, model, optimizer, scheduler, criterion, device):\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    model.train()\n",
        "    for data, target in tqdm(loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        correct += (out.argmax(1) == target).sum().item()\n",
        "    scheduler.step()\n",
        "    return running_loss, correct"
      ],
      "metadata": {
        "id": "0xhHJwsHCkyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "iU1gkYIbOeo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#instance\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#------------------------#\n",
        "loader = get_loader('cifar10', split='train', batch_size=128, DA=False)\n",
        "N = len(loader.dataset)\n",
        "#------------------------#\n",
        "model = S_Xception(4).to(device)\n",
        "#------------------------#\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.2)\n",
        "scheduler1 = lrs.CosineAnnealingLR(optimizer, T_max=8, eta_min=0.1, total_iters=8)\n",
        "#------------------------#\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "'''\n",
        "wandb.login()\n",
        "run = wandb.init(\n",
        "    project = 'name',\n",
        "    config = {\n",
        "        'Architecture': 'x',\n",
        "        'optim': 'Adam(1e-3)',\n",
        "        'sche1': 'x',\n",
        "        'sche2': 'x',\n",
        "        'sche': 'x',\n",
        "        'criterion': 'x',\n",
        "        'Data': 'Cifar10',\n",
        "        'else': 'x'\n",
        "    }\n",
        ")\n",
        "'''\n",
        "#train\n",
        "start_epoch = 0\n",
        "epochs = 8\n",
        "for epoch in range(start_epoch, epochs):\n",
        "    loss, correct = train_(loader, model, optimizer, scheduler1, criterion, device)\n",
        "    print(f'Epoch: {epoch} | loss: {loss} | acc: {correct*100/N}%')\n",
        "\n",
        "#save_checkpoint('!!!', simclr, optimizer, scheduler)"
      ],
      "metadata": {
        "id": "QmItM26uDVoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21fecf7f-6481-49d0-e918-61df71931dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [00:32<00:00, 12.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | loss: 732.2418007850647 | acc: 28.482%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [00:31<00:00, 12.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | loss: 611.673143029213 | acc: 41.548%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [00:31<00:00, 12.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 | loss: 556.4308239221573 | acc: 47.2%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [00:32<00:00, 12.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 | loss: 519.8156929016113 | acc: 50.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [00:31<00:00, 12.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 | loss: 490.36688554286957 | acc: 54.042%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [00:31<00:00, 12.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5 | loss: 463.4905755519867 | acc: 56.954%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [00:32<00:00, 12.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 | loss: 444.6516178846359 | acc: 58.702%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [00:31<00:00, 12.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7 | loss: 425.8461194038391 | acc: 60.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SResNet14(4) | Cifar10 | sf=default | lr=2e-3 | MultiStep([4, 6], 0.75) | 1min/epoch | 0 1077, 49.232% -> 1 757, 65.62% -->> 4 392, 82.526% -->> 9 150, 93.22% testは79.65%\n",
        "#SResNet14_group2(4) downsample(stride=2) | Cifar10 | lr=default | 40s/epoch | 33% -->> 10ep, 69.9%\n",
        "# 上との対照実験group=1 | 33% -->> 73%\n",
        "# 上との対照実験stride=3 | 30% -->> 73%\n",
        "# 上との対照実験channel半分 | 29% -->> 63%\n",
        "\n",
        "#11/11\n",
        "# ResNet()"
      ],
      "metadata": {
        "id": "f0JIM2M5IHYc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}