{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkkVzyjtaOgeXpuPL6/dkG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kazuto-Takahashi/Research/blob/main/IFneuron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn1zp02jjuCW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snntorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I8JxRQD4HzQl",
        "outputId": "76d94f63-03ea-4b44-e105-d123af964f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.1-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.4.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from snntorch) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.26.4)\n",
            "Collecting nir (from snntorch)\n",
            "  Downloading nir-1.0.4-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting nirtorch (from snntorch)\n",
            "  Downloading nirtorch-1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nir->snntorch) (3.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->snntorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->snntorch) (1.3.0)\n",
            "Downloading snntorch-0.9.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nir-1.0.4-py3-none-any.whl (18 kB)\n",
            "Downloading nirtorch-1.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: nir, nirtorch, snntorch\n",
            "Successfully installed nir-1.0.4 nirtorch-1.0 snntorch-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import snntorch as snn\n",
        "import snntorch.functional as SF"
      ],
      "metadata": {
        "id": "JCIr5km7H25N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuron Definition"
      ],
      "metadata": {
        "id": "UZ-7fW5cAB8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class surrogate_activation(torch.autograd.Function):\n",
        "  @staticmethod\n",
        "  def forward(ctx, input, thresh):\n",
        "    ctx.save_for_backward(input)\n",
        "    return torch.where(input < thresh, 0., 1.)\n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_input):\n",
        "    input, = ctx.saved_tensors\n",
        "    grad = 1 / (25 * torch.abs(input) + 1.0)\n",
        "    return grad_input * grad, None #このNoneはforward(thresh)に対応"
      ],
      "metadata": {
        "id": "j3VyKOQ9p3xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IF(nn.Module):\n",
        "  def __init__(self, thresh = 1.0, leak = 1.0):\n",
        "    super(IF, self).__init__()\n",
        "    self.mem = None\n",
        "    self.thresh = thresh\n",
        "    self.leak = leak\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.mem is None:\n",
        "      self.mem = torch.zeros_like(x)\n",
        "\n",
        "    self.mem = self.mem + x\n",
        "    spike = surrogate_activation.apply(self.mem, self.thresh)\n",
        "    self.mem = self.mem - spike\n",
        "    return spike"
      ],
      "metadata": {
        "id": "HG_WzV6Cj1gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preview"
      ],
      "metadata": {
        "id": "Gt4M_KUuua2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor([0.3, 0.4, 0.5], requires_grad=True)\n",
        "\n",
        "if_neuron = IF()\n",
        "\n",
        "spike_pot = []\n",
        "for i in range(4):\n",
        "  out = if_neuron(data)\n",
        "  spike_pot.append(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J2GZPRbDueI5",
        "outputId": "fc65906b-ff92-4cdf-cd9d-b4b4d15c8017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([0., 0., 0.], dtype=torch.float64,\n",
            "       grad_fn=<surrogate_activationBackward>)]\n",
            "[tensor([0., 0., 0.], dtype=torch.float64,\n",
            "       grad_fn=<surrogate_activationBackward>), tensor([0., 0., 1.], dtype=torch.float64,\n",
            "       grad_fn=<surrogate_activationBackward>)]\n",
            "[tensor([0., 0., 0.], dtype=torch.float64,\n",
            "       grad_fn=<surrogate_activationBackward>), tensor([0., 0., 1.], dtype=torch.float64,\n",
            "       grad_fn=<surrogate_activationBackward>), tensor([0., 1., 0.], dtype=torch.float64,\n",
            "       grad_fn=<surrogate_activationBackward>)]\n",
            "[tensor([0., 0., 0.], dtype=torch.float64,\n",
            "       grad_fn=<surrogate_activationBackward>), tensor([0., 0., 1.], dtype=torch.float64,\n",
            "       grad_fn=<surrogate_activationBackward>), tensor([0., 1., 0.], dtype=torch.float64,\n",
            "       grad_fn=<surrogate_activationBackward>), tensor([1., 0., 1.], dtype=torch.float64,\n",
            "       grad_fn=<surrogate_activationBackward>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = torch.tensor([0.3, 0.4, 0.5], requires_grad=True)\n",
        "\n",
        "if_neuron = IF()\n",
        "\n",
        "out = if_neuron(data1)\n",
        "loss = out.sum()\n",
        "loss.backward()\n",
        "\n",
        "print(data1.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSjPmxrNx9PD",
        "outputId": "cfece116-e150-45eb-a836-d42166eb1f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1176, 0.0909, 0.0741])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST"
      ],
      "metadata": {
        "id": "m2vKj8C4_NMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "6ciTMFFg_OkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.25,))])\n",
        "\n",
        "train = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
        "\n",
        "tr_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
        "ts_loader = DataLoader(test, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "GZvVonoD_lY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear1 = nn.Linear(784, 784)\n",
        "    self.act1 = IF()\n",
        "    self.linear2 = nn.Linear(784, 10)\n",
        "    self.act2 = IF()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    x = self.linear1(x)\n",
        "    x = self.act1(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.act2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "MOldgC6e4KMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = SF.ce_count_loss()"
      ],
      "metadata": {
        "id": "pMV-UcpgCFUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "\n",
        "epochs = 1\n",
        "steps = 1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  for idx, (data, target) in tqdm(enumerate(tr_loader)):\n",
        "    optimizer.zero_grad()\n",
        "    out_rec = []\n",
        "    for step in range(steps):\n",
        "      out = model(data)\n",
        "      out_rec.append(out)\n",
        "    out_stc = torch.stack(out_rec)\n",
        "    loss = criterion(out_stc, target)\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "\n",
        "    if idx % 50 == 0:\n",
        "      print(f'idx: {idx}, loss:{loss.item()}')\n",
        "  print(f'idx: {idx}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "ZkGSJrym5LWc",
        "outputId": "c16ffd63-49dc-4525-d8e7-53c67150f7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:00, 35.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx: 0, loss:2.3025851249694824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:04,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx: 50, loss:2.288417339324951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:16,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx: 100, loss:2.3633053302764893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "122it [00:23,  5.26it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-4f87d9cf1838>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mout_stc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_rec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_stc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \"\"\"\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         r\"\"\"\n\u001b[1;32m    293\u001b[0m         \u001b[0mApply\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mused\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mexecuting\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mNode\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}